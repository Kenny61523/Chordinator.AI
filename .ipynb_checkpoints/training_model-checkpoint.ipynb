{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ad08da8a-5640-494a-8761-058410b09a8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\charl\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\scipy\\__init__.py:155: UserWarning: A NumPy version >=1.18.5 and <1.25.0 is required for this version of SciPy (detected version 1.26.3\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a4226bd7-ad29-4ced-90ee-c044c2dee750",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\charl\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM, Flatten, RepeatVector, TimeDistributed\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from keras import backend as K\n",
    "import generate_valid_prediction\n",
    "from keras.models import save_model, load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "723141b0-ed12-494e-9a50-9357ff75aad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "note_mapping = {\n",
    "    'C0': 1, 'C#0': 2, 'D0': 3, 'D#0': 4, 'E0': 5, 'F0': 6, 'F#0': 7, 'G0': 8, 'G#0': 9, 'A1': 10,\n",
    "    'A#1': 11, 'B1': 12, 'C1': 13, 'C#1': 14, 'D1': 15, 'D#1': 16, 'E1': 17, 'F1': 18, 'F#1': 19,\n",
    "    'G1': 20, 'G#1': 21, 'A2': 22, 'A#2': 23, 'B2': 24, 'C2': 25, 'C#2': 26, 'D2': 27, 'D#2': 28,\n",
    "    'E2': 29, 'F2': 30, 'F#2': 31, 'G2': 32, 'G#2': 33, 'A3': 34, 'A#3': 35, 'B3': 36, 'C3': 37,\n",
    "    'C#3': 38, 'D3': 39, 'D#3': 40, 'E3': 41, 'F3': 42, 'F#3': 43, 'G3': 44, 'G#3': 45, 'A4': 46,\n",
    "    'A#4': 47, 'B4': 48, 'C4': 49, 'C#4': 50, 'D4': 51, 'D#4': 52, 'E4': 53, 'F4': 54, 'F#4': 55,\n",
    "    'G4': 56, 'G#4': 57, 'A5': 58, 'A#5': 59, 'B5': 60, 'C5': 61, 'C#5': 62, 'D5': 63, 'D#5': 64,\n",
    "    'E5': 65, 'F5': 66, 'F#5': 67, 'G5': 68, 'G#5': 69, 'A6': 70, 'A#6': 71, 'B6': 72, 'C6': 73\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ec0fe328-62e8-403b-89b3-3ea7ea35803a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_1 = [\n",
    "    (['C1', 'G1', 'A1', 'F1'], (['C1', 'E1', 'G1'], ['G1', 'B2', 'D2'], ['A1', 'C1', 'E1'], ['F1', 'A2', 'C2'])),\n",
    "    (['C4', 'F4', 'G4', 'A5'], (['C4', 'E4', 'G4'], ['F4', 'C5', 'A5'], ['G4', 'B5', 'D5'], ['A5', 'C5', 'A6'])),\n",
    "    (['C2', 'D2', 'F2', 'G2'], (['C2', 'G2', 'E3'], ['D2', 'A3', 'F2', 'D3'], ['F2', 'A3', 'C3'], ['G2', 'B3', 'D3']))\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3b990309-2784-4416-bc12-2f796d5e374e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_notes(notes):\n",
    "    return [note_mapping[note] for note in notes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6c9e8e65-235e-47c4-9002-521f3fd579e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(\"chord_output.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "89bd0197-1303-4957-b0cc-35d51d7fb75c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here's X:\n",
      "[[1 5 4 6]\n",
      " [1 5 4 6]\n",
      " [1 5 4 6]\n",
      " [1 5 6 4]\n",
      " [1 5 6 4]\n",
      " [1 5 6 4]\n",
      " [1 6 4 5]\n",
      " [1 6 4 5]\n",
      " [1 6 4 5]\n",
      " [1 6 5 4]\n",
      " [1 6 5 4]\n",
      " [1 6 5 4]\n",
      " [1 6 5 4]\n",
      " [1 6 5 4]\n",
      " [2 4 6 5]\n",
      " [2 4 6 5]\n",
      " [3 5 6 1]\n",
      " [3 5 6 1]\n",
      " [3 5 6 1]\n",
      " [3 5 6 1]\n",
      " [3 5 6 3]\n",
      " [3 5 6 3]\n",
      " [4 1 5 3]\n",
      " [4 1 5 4]\n",
      " [4 1 5 4]\n",
      " [4 1 5 4]\n",
      " [4 1 5 4]\n",
      " [4 1 6 5]\n",
      " [4 1 6 5]\n",
      " [4 1 6 5]\n",
      " [4 1 6 5]\n",
      " [4 1 6 5]\n",
      " [4 3 6 5]\n",
      " [4 3 6 5]\n",
      " [4 3 6 5]\n",
      " [4 5 6 1]\n",
      " [4 5 6 1]\n",
      " [4 5 6 1]\n",
      " [4 5 6 1]\n",
      " [4 6 5 3]\n",
      " [4 6 5 3]\n",
      " [6 1 2 4]\n",
      " [6 1 2 4]\n",
      " [6 1 2 4]\n",
      " [6 1 3 4]\n",
      " [6 1 3 4]\n",
      " [6 1 3 4]\n",
      " [6 1 4 5]\n",
      " [6 1 4 5]\n",
      " [6 1 4 5]\n",
      " [6 1 5 2]\n",
      " [6 1 5 2]\n",
      " [6 1 5 4]\n",
      " [6 1 5 4]\n",
      " [6 1 5 4]\n",
      " [6 1 5 4]\n",
      " [6 1 6 5]\n",
      " [6 1 6 5]\n",
      " [6 1 6 5]\n",
      " [6 2 4 5]\n",
      " [6 2 4 5]\n",
      " [6 2 4 5]\n",
      " [6 2 4 5]\n",
      " [6 2 5 1]\n",
      " [6 2 5 1]\n",
      " [6 2 5 1]\n",
      " [6 2 5 1]]\n",
      "Here's y:\n",
      "[[[26 24 22 15]\n",
      "  [30 21 26 19]\n",
      "  [29 20 25 18]\n",
      "  [31 29 20 13]]\n",
      "\n",
      " [[33 31 29 15]\n",
      "  [33 30 21 19]\n",
      "  [27 32 29 18]\n",
      "  [27 31 29 13]]\n",
      "\n",
      " [[33 31 29 15]\n",
      "  [30 21 26 19]\n",
      "  [32 29 20 18]\n",
      "  [31 29 20 13]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[27 31 29 13]\n",
      "  [32 30 23 20]\n",
      "  [33 30 21 19]\n",
      "  [31 29 26 22]]\n",
      "\n",
      " [[29 20 24 13]\n",
      "  [20 25 23 16]\n",
      "  [21 26 23 19]\n",
      "  [26 24 22 15]]\n",
      "\n",
      " [[29 20 24 13]\n",
      "  [30 20 25 16]\n",
      "  [30 21 26 19]\n",
      "  [31 29 26 22]]]\n"
     ]
    }
   ],
   "source": [
    "# Process the dataset\n",
    "X_train = []\n",
    "y_train = []\n",
    "X_test = []\n",
    "y_test = []\n",
    "\n",
    "#-----------------------------------------------\n",
    "# for base_notes, chord_progressions in dataset_1:\n",
    "#     # Encode base notes\n",
    "#     encoded_base_notes = encode_notes(base_notes)\n",
    "\n",
    "#     # print(base_notes)\n",
    "\n",
    "#     # Encode and pad chord progressions\n",
    "#     encoded_chord_progressions = [encode_notes(chord) for chord in chord_progressions]\n",
    "#     print(type(encoded_chord_progressions))\n",
    "#     padded_chord_progressions = pad_sequences(encoded_chord_progressions, maxlen=6, padding='post')\n",
    "\n",
    "#     # Create input-output pairs\n",
    "#     X_train.append(encoded_base_notes)\n",
    "#     y_train.append(padded_chord_progressions)\n",
    "\n",
    "# X_train = np.array(X_train)\n",
    "# y_train = np.array(y_train)\n",
    "\n",
    "# # print(\"Here's X:\")\n",
    "# # print(X_train)\n",
    "# # print(\"Here's y:\")\n",
    "# # print(y_train)\n",
    "#----------------------------------------------\n",
    "\n",
    "# # Split the data into training and validation sets\n",
    "# train_data, val_data = train_test_split(dataset, test_size=0.2, random_state=42)\n",
    "\n",
    "# # Prepare training data\n",
    "# X_train = np.array(train_data['base_notes'].tolist())\n",
    "# y_train = np.array(train_data['chord_progressions'].tolist())\n",
    "\n",
    "# # Convert string representations to lists\n",
    "# X_train = [ast.literal_eval(x) for x in X_train]\n",
    "# y_train = [ast.literal_eval(y) for y in y_train]\n",
    "\n",
    "# X_train = np.array(X_train)\n",
    "# y_train = np.array(y_train)\n",
    "\n",
    "num_lines = 83\n",
    "test_amt = 16\n",
    "\n",
    "for i in range(num_lines - test_amt):\n",
    "    base_note = ast.literal_eval(dataset[\"base_notes\"][i])\n",
    "    chord_progression_raw = ast.literal_eval(dataset[\"chord_progressions\"][i])\n",
    "\n",
    "    chord_progression = pad_sequences(chord_progression_raw, maxlen=4, padding='post')\n",
    "    \n",
    "    X_train.append(base_note)\n",
    "    y_train.append(chord_progression)\n",
    "\n",
    "# print(np.array(dataset[\"base_notes\"][99]))\n",
    "\n",
    "X_train = np.array(X_train)\n",
    "y_train = np.array(y_train)\n",
    "\n",
    "\n",
    "for i in range(num_lines - test_amt, num_lines):\n",
    "    base_note = ast.literal_eval(dataset[\"base_notes\"][i])\n",
    "    chord_progression_raw = ast.literal_eval(dataset[\"chord_progressions\"][i])\n",
    "\n",
    "    chord_progression = pad_sequences(chord_progression_raw, maxlen=4, padding='post')\n",
    "    \n",
    "    X_test.append(base_note)\n",
    "    y_test.append(chord_progression)\n",
    "\n",
    "# print(np.array(dataset[\"base_notes\"][99]))\n",
    "\n",
    "X_test = np.array(X_test)\n",
    "y_test = np.array(y_test)\n",
    "\n",
    "print(\"Here's X:\")\n",
    "print(X_train)\n",
    "print(\"Here's y:\")\n",
    "print(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "269fb882-a4d1-4a4a-8860-5b41a7979ad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_loss(y_true, y_pred):\n",
    "    # Assuming y_true and y_pred are of shape (batch_size, sequence_length, num_classes)\n",
    "    base_note_index = 0\n",
    "    \n",
    "    # Custom logic to penalize if base note is not present in the predicted output\n",
    "    loss = K.categorical_crossentropy(K.cast(y_true, dtype='float32'), y_pred) + 1 * K.mean(1 - K.cast(y_pred[:, base_note_index], dtype='float32'))\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5f40907a-2d02-4352-9941-cd6380e45c28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\charl\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# model = Sequential()\n",
    "# model.add(Dense(units=128, activation = \"relu\"))\n",
    "# model.add(Dense(units=4, activation='softmax'))\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(units=128, activation=\"softmax\", input_shape=(4,)))\n",
    "model.add(RepeatVector(4))  # Repeat the vector to match the number of timesteps\n",
    "model.add(LSTM(units=64, return_sequences=True))\n",
    "model.add(LSTM(units=32, return_sequences=True))\n",
    "model.add(TimeDistributed(Dense(units=4, activation='softmax')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "16522a8a-8045-493b-b295-268fc917938c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\charl\\AppData\\Local\\Temp\\ipykernel_22328\\869453306.py:1: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer=tf.compat.v1.train.AdamOptimizer(), loss=custom_loss, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "05764cda-6fae-4c47-af77-6643e3d05fc4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "WARNING:tensorflow:From C:\\Users\\charl\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\charl\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "53/53 [==============================] - 4s 22ms/step - loss: 130.9673 - accuracy: 0.7500 - val_loss: 119.0178 - val_accuracy: 0.7500\n",
      "Epoch 2/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 130.5728 - accuracy: 0.7500 - val_loss: 118.8273 - val_accuracy: 0.7500\n",
      "Epoch 3/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 130.4705 - accuracy: 0.7500 - val_loss: 118.6854 - val_accuracy: 0.7500\n",
      "Epoch 4/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 130.4185 - accuracy: 0.7500 - val_loss: 118.6087 - val_accuracy: 0.7500\n",
      "Epoch 5/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 130.3913 - accuracy: 0.7500 - val_loss: 118.7409 - val_accuracy: 0.7500\n",
      "Epoch 6/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 130.3790 - accuracy: 0.7500 - val_loss: 118.6146 - val_accuracy: 0.7500\n",
      "Epoch 7/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 130.3727 - accuracy: 0.7500 - val_loss: 118.6614 - val_accuracy: 0.7500\n",
      "Epoch 8/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 130.3761 - accuracy: 0.7500 - val_loss: 118.6075 - val_accuracy: 0.7500\n",
      "Epoch 9/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 130.3581 - accuracy: 0.7500 - val_loss: 118.5369 - val_accuracy: 0.7500\n",
      "Epoch 10/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 130.3561 - accuracy: 0.7500 - val_loss: 118.5395 - val_accuracy: 0.7500\n",
      "Epoch 11/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 130.3576 - accuracy: 0.7500 - val_loss: 118.5069 - val_accuracy: 0.7500\n",
      "Epoch 12/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 130.3541 - accuracy: 0.7500 - val_loss: 118.5220 - val_accuracy: 0.7500\n",
      "Epoch 13/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 130.3500 - accuracy: 0.7500 - val_loss: 118.5262 - val_accuracy: 0.7500\n",
      "Epoch 14/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 130.3416 - accuracy: 0.7500 - val_loss: 118.4355 - val_accuracy: 0.7500\n",
      "Epoch 15/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 130.3332 - accuracy: 0.7500 - val_loss: 118.4446 - val_accuracy: 0.7500\n",
      "Epoch 16/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 130.3285 - accuracy: 0.7453 - val_loss: 118.3724 - val_accuracy: 0.7500\n",
      "Epoch 17/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 130.3173 - accuracy: 0.7500 - val_loss: 118.3323 - val_accuracy: 0.7500\n",
      "Epoch 18/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 130.3110 - accuracy: 0.7500 - val_loss: 118.2949 - val_accuracy: 0.7500\n",
      "Epoch 19/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 130.3046 - accuracy: 0.7500 - val_loss: 118.2833 - val_accuracy: 0.7500\n",
      "Epoch 20/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 130.2995 - accuracy: 0.7453 - val_loss: 118.2378 - val_accuracy: 0.7500\n",
      "Epoch 21/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 130.2937 - accuracy: 0.7453 - val_loss: 118.2085 - val_accuracy: 0.7500\n",
      "Epoch 22/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 130.2866 - accuracy: 0.7500 - val_loss: 118.2428 - val_accuracy: 0.7500\n",
      "Epoch 23/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 130.2873 - accuracy: 0.7453 - val_loss: 118.2300 - val_accuracy: 0.7500\n",
      "Epoch 24/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 130.2798 - accuracy: 0.7500 - val_loss: 118.2004 - val_accuracy: 0.7500\n",
      "Epoch 25/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 130.2737 - accuracy: 0.7500 - val_loss: 118.1684 - val_accuracy: 0.7500\n",
      "Epoch 26/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 130.2671 - accuracy: 0.7500 - val_loss: 118.1894 - val_accuracy: 0.7500\n",
      "Epoch 27/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 130.2700 - accuracy: 0.7500 - val_loss: 118.2291 - val_accuracy: 0.7500\n",
      "Epoch 28/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 130.2685 - accuracy: 0.7500 - val_loss: 118.2287 - val_accuracy: 0.7500\n",
      "Epoch 29/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 130.2668 - accuracy: 0.7453 - val_loss: 118.2538 - val_accuracy: 0.7500\n",
      "Epoch 30/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 130.2546 - accuracy: 0.7500 - val_loss: 118.1931 - val_accuracy: 0.7500\n",
      "Epoch 31/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 130.2556 - accuracy: 0.7500 - val_loss: 118.2113 - val_accuracy: 0.7500\n",
      "Epoch 32/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 130.2641 - accuracy: 0.7500 - val_loss: 118.1224 - val_accuracy: 0.7500\n",
      "Epoch 33/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 130.2497 - accuracy: 0.7547 - val_loss: 118.3244 - val_accuracy: 0.7500\n",
      "Epoch 34/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 130.2595 - accuracy: 0.7500 - val_loss: 118.2212 - val_accuracy: 0.7500\n",
      "Epoch 35/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 130.2526 - accuracy: 0.7500 - val_loss: 118.1957 - val_accuracy: 0.7500\n",
      "Epoch 36/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 130.2566 - accuracy: 0.7500 - val_loss: 118.1625 - val_accuracy: 0.7500\n",
      "Epoch 37/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 130.2474 - accuracy: 0.7500 - val_loss: 118.1749 - val_accuracy: 0.7500\n",
      "Epoch 38/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 130.2449 - accuracy: 0.7500 - val_loss: 118.2045 - val_accuracy: 0.7500\n",
      "Epoch 39/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 130.2378 - accuracy: 0.7500 - val_loss: 118.1285 - val_accuracy: 0.7500\n",
      "Epoch 40/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 130.2345 - accuracy: 0.7500 - val_loss: 118.2485 - val_accuracy: 0.7500\n",
      "Epoch 41/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 130.2422 - accuracy: 0.7500 - val_loss: 118.1683 - val_accuracy: 0.7500\n",
      "Epoch 42/100\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 130.2252 - accuracy: 0.7500 - val_loss: 118.2334 - val_accuracy: 0.7500\n",
      "Epoch 43/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 130.2400 - accuracy: 0.7500 - val_loss: 118.2075 - val_accuracy: 0.7500\n",
      "Epoch 44/100\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 130.2271 - accuracy: 0.7500 - val_loss: 118.1664 - val_accuracy: 0.7500\n",
      "Epoch 45/100\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 130.1969 - accuracy: 0.7500 - val_loss: 118.2112 - val_accuracy: 0.7500\n",
      "Epoch 46/100\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 130.2106 - accuracy: 0.7500 - val_loss: 118.2713 - val_accuracy: 0.7500\n",
      "Epoch 47/100\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 130.1921 - accuracy: 0.7500 - val_loss: 118.3170 - val_accuracy: 0.7500\n",
      "Epoch 48/100\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 130.1858 - accuracy: 0.7500 - val_loss: 118.2101 - val_accuracy: 0.7500\n",
      "Epoch 49/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 130.1787 - accuracy: 0.7500 - val_loss: 118.1732 - val_accuracy: 0.7500\n",
      "Epoch 50/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 130.1800 - accuracy: 0.7500 - val_loss: 118.2026 - val_accuracy: 0.7500\n",
      "Epoch 51/100\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 130.1822 - accuracy: 0.7500 - val_loss: 118.2615 - val_accuracy: 0.7500\n",
      "Epoch 52/100\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 130.1815 - accuracy: 0.7500 - val_loss: 118.1642 - val_accuracy: 0.7500\n",
      "Epoch 53/100\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 130.1719 - accuracy: 0.7500 - val_loss: 118.1702 - val_accuracy: 0.7500\n",
      "Epoch 54/100\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 130.1667 - accuracy: 0.7500 - val_loss: 118.1640 - val_accuracy: 0.7500\n",
      "Epoch 55/100\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 130.1721 - accuracy: 0.7500 - val_loss: 118.2338 - val_accuracy: 0.7500\n",
      "Epoch 56/100\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 130.1670 - accuracy: 0.7500 - val_loss: 118.2400 - val_accuracy: 0.7500\n",
      "Epoch 57/100\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 130.1607 - accuracy: 0.7500 - val_loss: 118.1523 - val_accuracy: 0.7500\n",
      "Epoch 58/100\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 130.1580 - accuracy: 0.7500 - val_loss: 118.2433 - val_accuracy: 0.7500\n",
      "Epoch 59/100\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 130.1644 - accuracy: 0.7500 - val_loss: 118.2810 - val_accuracy: 0.7500\n",
      "Epoch 60/100\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 130.1688 - accuracy: 0.7500 - val_loss: 118.2187 - val_accuracy: 0.7500\n",
      "Epoch 61/100\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 130.1760 - accuracy: 0.7500 - val_loss: 118.1998 - val_accuracy: 0.7500\n",
      "Epoch 62/100\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 130.1540 - accuracy: 0.7500 - val_loss: 118.2202 - val_accuracy: 0.7500\n",
      "Epoch 63/100\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 130.1599 - accuracy: 0.7500 - val_loss: 118.1964 - val_accuracy: 0.7500\n",
      "Epoch 64/100\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 130.1691 - accuracy: 0.7500 - val_loss: 118.1827 - val_accuracy: 0.7500\n",
      "Epoch 65/100\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 130.1535 - accuracy: 0.7500 - val_loss: 118.1774 - val_accuracy: 0.7500\n",
      "Epoch 66/100\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 130.1566 - accuracy: 0.7500 - val_loss: 118.2320 - val_accuracy: 0.7500\n",
      "Epoch 67/100\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 130.1525 - accuracy: 0.7500 - val_loss: 118.1813 - val_accuracy: 0.7500\n",
      "Epoch 68/100\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 130.1624 - accuracy: 0.7500 - val_loss: 118.1896 - val_accuracy: 0.7500\n",
      "Epoch 69/100\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 130.1517 - accuracy: 0.7500 - val_loss: 118.1962 - val_accuracy: 0.7500\n",
      "Epoch 70/100\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 130.1608 - accuracy: 0.7500 - val_loss: 118.2223 - val_accuracy: 0.7500\n",
      "Epoch 71/100\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 130.1531 - accuracy: 0.7500 - val_loss: 118.1672 - val_accuracy: 0.7500\n",
      "Epoch 72/100\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 130.1512 - accuracy: 0.7500 - val_loss: 118.1993 - val_accuracy: 0.7500\n",
      "Epoch 73/100\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 130.1508 - accuracy: 0.7500 - val_loss: 118.1577 - val_accuracy: 0.7500\n",
      "Epoch 74/100\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 130.1534 - accuracy: 0.7358 - val_loss: 118.1785 - val_accuracy: 0.7500\n",
      "Epoch 75/100\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 130.1510 - accuracy: 0.7406 - val_loss: 118.1830 - val_accuracy: 0.7500\n",
      "Epoch 76/100\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 130.1490 - accuracy: 0.7453 - val_loss: 118.1877 - val_accuracy: 0.7500\n",
      "Epoch 77/100\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 130.1475 - accuracy: 0.7500 - val_loss: 118.1819 - val_accuracy: 0.7500\n",
      "Epoch 78/100\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 130.1521 - accuracy: 0.7500 - val_loss: 118.1613 - val_accuracy: 0.7500\n",
      "Epoch 79/100\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 130.1358 - accuracy: 0.7500 - val_loss: 118.1701 - val_accuracy: 0.7500\n",
      "Epoch 80/100\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 130.1382 - accuracy: 0.7500 - val_loss: 118.2723 - val_accuracy: 0.7500\n",
      "Epoch 81/100\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 130.1664 - accuracy: 0.7500 - val_loss: 118.1786 - val_accuracy: 0.7500\n",
      "Epoch 82/100\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 130.1434 - accuracy: 0.7500 - val_loss: 118.2417 - val_accuracy: 0.7500\n",
      "Epoch 83/100\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 130.1333 - accuracy: 0.7453 - val_loss: 118.1612 - val_accuracy: 0.7500\n",
      "Epoch 84/100\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 130.1420 - accuracy: 0.7500 - val_loss: 118.1938 - val_accuracy: 0.7500\n",
      "Epoch 85/100\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 130.1484 - accuracy: 0.7500 - val_loss: 118.1524 - val_accuracy: 0.7500\n",
      "Epoch 86/100\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 130.1478 - accuracy: 0.7453 - val_loss: 118.2047 - val_accuracy: 0.7500\n",
      "Epoch 87/100\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 130.1399 - accuracy: 0.7453 - val_loss: 118.1587 - val_accuracy: 0.7500\n",
      "Epoch 88/100\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 130.1472 - accuracy: 0.7406 - val_loss: 118.1797 - val_accuracy: 0.7500\n",
      "Epoch 89/100\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 130.1344 - accuracy: 0.7547 - val_loss: 118.2090 - val_accuracy: 0.7500\n",
      "Epoch 90/100\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 130.1348 - accuracy: 0.7453 - val_loss: 118.1426 - val_accuracy: 0.7500\n",
      "Epoch 91/100\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 130.1331 - accuracy: 0.7500 - val_loss: 118.2243 - val_accuracy: 0.7500\n",
      "Epoch 92/100\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 130.1328 - accuracy: 0.7547 - val_loss: 118.2242 - val_accuracy: 0.7500\n",
      "Epoch 93/100\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 130.1315 - accuracy: 0.7406 - val_loss: 118.2149 - val_accuracy: 0.7500\n",
      "Epoch 94/100\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 130.1252 - accuracy: 0.7406 - val_loss: 118.2439 - val_accuracy: 0.7500\n",
      "Epoch 95/100\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 130.1262 - accuracy: 0.7500 - val_loss: 118.2135 - val_accuracy: 0.7500\n",
      "Epoch 96/100\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 130.1359 - accuracy: 0.7547 - val_loss: 118.1876 - val_accuracy: 0.7500\n",
      "Epoch 97/100\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 130.1253 - accuracy: 0.7453 - val_loss: 118.2367 - val_accuracy: 0.7500\n",
      "Epoch 98/100\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 130.1219 - accuracy: 0.7453 - val_loss: 118.2716 - val_accuracy: 0.7500\n",
      "Epoch 99/100\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 130.1207 - accuracy: 0.7500 - val_loss: 118.1777 - val_accuracy: 0.7500\n",
      "Epoch 100/100\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 130.1255 - accuracy: 0.7500 - val_loss: 118.2310 - val_accuracy: 0.7500\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x2af64965ca0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=100, batch_size=1, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ce68cb68-64fe-4ce7-aecb-5898aa598210",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\charl\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "model.save(\"first_version.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f790470d-a021-4679-815d-223a4c6278d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\charl\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\src\\backend.py:1398: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "1/1 [==============================] - 1s 1s/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[[0.29437378, 0.26178554, 0.25390577, 0.1899349 ],\n",
       "        [0.30581456, 0.26259905, 0.25224227, 0.17934412],\n",
       "        [0.3229772 , 0.27285716, 0.2473667 , 0.15679888],\n",
       "        [0.3057361 , 0.2555947 , 0.25572714, 0.18294205]]], dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_model = load_model(\"first_version.h5\", custom_objects={'custom_loss': custom_loss})\n",
    "loaded_model.predict(np.array([[4, 2, 5, 6]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4c384453-35e2-428d-91b1-7047bf20cee7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 5 6 4]\n"
     ]
    }
   ],
   "source": [
    "print(np.array([1, 5, 6, 4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "942363cf-34c9-4410-81b0-08f7491bccbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from validity_function import validity_function\n",
    "\n",
    "def generate_valid_prediction(model, input_sequence):\n",
    "    while True:\n",
    "        prediction = model.predict(np.array([input_sequence]))\n",
    "        if validity_function(input_sequence, prediction):\n",
    "            return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "26f726a0-1de7-4342-a47b-7779cd57a4b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 40ms/step\n",
      "1\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mgenerate_valid_prediction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloaded_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m6\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# model.predict(np.array([[1, 4, 5, 6]]))\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[11], line 6\u001b[0m, in \u001b[0;36mgenerate_valid_prediction\u001b[1;34m(model, input_sequence)\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m      5\u001b[0m     prediction \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(np\u001b[38;5;241m.\u001b[39marray([input_sequence]))\n\u001b[1;32m----> 6\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mvalidity_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_sequence\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprediction\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m      7\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m prediction\n",
      "File \u001b[1;32m~\\UofTHacks11\\Chordinator.AI\\validity_function.py:7\u001b[0m, in \u001b[0;36mvalidity_function\u001b[1;34m(base_notes, chord_progression)\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(base_notes[i])\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m4\u001b[39m):\n\u001b[1;32m----> 7\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28;43mabs\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mbase_notes\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mchord_progression\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43mj\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m%\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m7\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m \u001b[38;5;129;01mor\u001b[39;00m \n\u001b[0;32m      8\u001b[0m         \u001b[38;5;28mabs\u001b[39m(base_notes[i] \u001b[38;5;241m-\u001b[39m chord_progression[i][j]) \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m7\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m \n\u001b[0;32m      9\u001b[0m         \u001b[38;5;28mabs\u001b[39m(base_notes[i] \u001b[38;5;241m-\u001b[39m chord_progression[i][j]) \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m7\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m4\u001b[39m):\n\u001b[0;32m     10\u001b[0m         validity_array\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     11\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;31mValueError\u001b[0m: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()"
     ]
    }
   ],
   "source": [
    "generate_valid_prediction(loaded_model, [1, 4, 5, 6])\n",
    "# model.predict(np.array([[1, 4, 5, 6]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a8af1afb-6910-4072-9838-a97f025ead6b",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m loss, accuracy \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241m.\u001b[39mevaluate(X_test, y_test)\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTest Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mloss\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Test Accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00maccuracy\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f'Test Loss: {loss}, Test Accuracy: {accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "26c74747-0b36-4746-9224-9781170aabe9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 32ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[[0.29437378, 0.26178554, 0.25390577, 0.1899349 ],\n",
       "        [0.30581456, 0.26259905, 0.25224227, 0.17934412],\n",
       "        [0.3229772 , 0.27285716, 0.2473667 , 0.15679888],\n",
       "        [0.3057361 , 0.2555947 , 0.25572714, 0.18294205]]], dtype=float32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(np.array([[4, 2, 5, 6]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88731800-94f9-4abe-9dff-1b1a7f3bdf08",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
