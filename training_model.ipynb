{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ad08da8a-5640-494a-8761-058410b09a8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\charl\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\scipy\\__init__.py:155: UserWarning: A NumPy version >=1.18.5 and <1.25.0 is required for this version of SciPy (detected version 1.26.3\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a4226bd7-ad29-4ced-90ee-c044c2dee750",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\charl\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM, Flatten, RepeatVector, TimeDistributed\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "723141b0-ed12-494e-9a50-9357ff75aad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "note_mapping = {\n",
    "    'C0': 1, 'C#0': 2, 'D0': 3, 'D#0': 4, 'E0': 5, 'F0': 6, 'F#0': 7, 'G0': 8, 'G#0': 9, 'A1': 10,\n",
    "    'A#1': 11, 'B1': 12, 'C1': 13, 'C#1': 14, 'D1': 15, 'D#1': 16, 'E1': 17, 'F1': 18, 'F#1': 19,\n",
    "    'G1': 20, 'G#1': 21, 'A2': 22, 'A#2': 23, 'B2': 24, 'C2': 25, 'C#2': 26, 'D2': 27, 'D#2': 28,\n",
    "    'E2': 29, 'F2': 30, 'F#2': 31, 'G2': 32, 'G#2': 33, 'A3': 34, 'A#3': 35, 'B3': 36, 'C3': 37,\n",
    "    'C#3': 38, 'D3': 39, 'D#3': 40, 'E3': 41, 'F3': 42, 'F#3': 43, 'G3': 44, 'G#3': 45, 'A4': 46,\n",
    "    'A#4': 47, 'B4': 48, 'C4': 49, 'C#4': 50, 'D4': 51, 'D#4': 52, 'E4': 53, 'F4': 54, 'F#4': 55,\n",
    "    'G4': 56, 'G#4': 57, 'A5': 58, 'A#5': 59, 'B5': 60, 'C5': 61, 'C#5': 62, 'D5': 63, 'D#5': 64,\n",
    "    'E5': 65, 'F5': 66, 'F#5': 67, 'G5': 68, 'G#5': 69, 'A6': 70, 'A#6': 71, 'B6': 72, 'C6': 73\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ec0fe328-62e8-403b-89b3-3ea7ea35803a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_1 = [\n",
    "    (['C1', 'G1', 'A1', 'F1'], (['C1', 'E1', 'G1'], ['G1', 'B2', 'D2'], ['A1', 'C1', 'E1'], ['F1', 'A2', 'C2'])),\n",
    "    (['C4', 'F4', 'G4', 'A5'], (['C4', 'E4', 'G4'], ['F4', 'C5', 'A5'], ['G4', 'B5', 'D5'], ['A5', 'C5', 'A6'])),\n",
    "    (['C2', 'D2', 'F2', 'G2'], (['C2', 'G2', 'E3'], ['D2', 'A3', 'F2', 'D3'], ['F2', 'A3', 'C3'], ['G2', 'B3', 'D3']))\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3b990309-2784-4416-bc12-2f796d5e374e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_notes(notes):\n",
    "    return [note_mapping[note] for note in notes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6c9e8e65-235e-47c4-9002-521f3fd579e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(\"output.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "89bd0197-1303-4957-b0cc-35d51d7fb75c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process the dataset\n",
    "X_train = []\n",
    "y_train = []\n",
    "\n",
    "#-----------------------------------------------\n",
    "# for base_notes, chord_progressions in dataset_1:\n",
    "#     # Encode base notes\n",
    "#     encoded_base_notes = encode_notes(base_notes)\n",
    "\n",
    "#     # print(base_notes)\n",
    "\n",
    "#     # Encode and pad chord progressions\n",
    "#     encoded_chord_progressions = [encode_notes(chord) for chord in chord_progressions]\n",
    "#     print(type(encoded_chord_progressions))\n",
    "#     padded_chord_progressions = pad_sequences(encoded_chord_progressions, maxlen=6, padding='post')\n",
    "\n",
    "#     # Create input-output pairs\n",
    "#     X_train.append(encoded_base_notes)\n",
    "#     y_train.append(padded_chord_progressions)\n",
    "\n",
    "# X_train = np.array(X_train)\n",
    "# y_train = np.array(y_train)\n",
    "\n",
    "# # print(\"Here's X:\")\n",
    "# # print(X_train)\n",
    "# # print(\"Here's y:\")\n",
    "# # print(y_train)\n",
    "#----------------------------------------------\n",
    "\n",
    "# # Split the data into training and validation sets\n",
    "# train_data, val_data = train_test_split(dataset, test_size=0.2, random_state=42)\n",
    "\n",
    "# # Prepare training data\n",
    "# X_train = np.array(train_data['base_notes'].tolist())\n",
    "# y_train = np.array(train_data['chord_progressions'].tolist())\n",
    "\n",
    "# # Convert string representations to lists\n",
    "# X_train = [ast.literal_eval(x) for x in X_train]\n",
    "# y_train = [ast.literal_eval(y) for y in y_train]\n",
    "\n",
    "# X_train = np.array(X_train)\n",
    "# y_train = np.array(y_train)\n",
    "\n",
    "num_lines = 99\n",
    "\n",
    "for i in range(num_lines):\n",
    "    base_note = ast.literal_eval(dataset[\"base_notes\"][i])\n",
    "    chord_progression_raw = ast.literal_eval(dataset[\"chord_progressions\"][i])\n",
    "\n",
    "    chord_progression = pad_sequences(chord_progression_raw, maxlen=6, padding='post')\n",
    "    \n",
    "    X_train.append(base_note)\n",
    "    y_train.append(chord_progression)\n",
    "\n",
    "# print(np.array(dataset[\"base_notes\"][99]))\n",
    "\n",
    "X_train = np.array(X_train)\n",
    "y_train = np.array(y_train)\n",
    "\n",
    "# print(\"Here's X:\")\n",
    "# print(X_train)\n",
    "# print(\"Here's y:\")\n",
    "# print(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5f40907a-2d02-4352-9941-cd6380e45c28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = Sequential()\n",
    "# model.add(Dense(units=128, activation = \"relu\"))\n",
    "# model.add(Dense(units=4, activation='softmax'))\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(units=128, activation=\"softmax\", input_shape=(4,)))\n",
    "model.add(RepeatVector(4))  # Repeat the vector to match the number of timesteps\n",
    "model.add(LSTM(units=64, return_sequences=True))\n",
    "model.add(LSTM(units=32, return_sequences=True))\n",
    "model.add(TimeDistributed(Dense(units=6, activation='softmax')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "16522a8a-8045-493b-b295-268fc917938c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=tf.compat.v1.train.AdamOptimizer(), loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "05764cda-6fae-4c47-af77-6643e3d05fc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 227.9121 - accuracy: 0.7278 - val_loss: 241.4352 - val_accuracy: 0.8375\n",
      "Epoch 2/100\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 227.9488 - accuracy: 0.7310 - val_loss: 241.4852 - val_accuracy: 0.6375\n",
      "Epoch 3/100\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 228.0468 - accuracy: 0.7152 - val_loss: 241.1183 - val_accuracy: 0.8375\n",
      "Epoch 4/100\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 227.9870 - accuracy: 0.7247 - val_loss: 241.5136 - val_accuracy: 0.8375\n",
      "Epoch 5/100\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 227.9337 - accuracy: 0.7310 - val_loss: 241.1582 - val_accuracy: 0.8375\n",
      "Epoch 6/100\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 227.8886 - accuracy: 0.7342 - val_loss: 242.1936 - val_accuracy: 0.8375\n",
      "Epoch 7/100\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 227.9202 - accuracy: 0.7215 - val_loss: 241.5746 - val_accuracy: 0.8375\n",
      "Epoch 8/100\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 227.8530 - accuracy: 0.7184 - val_loss: 241.7311 - val_accuracy: 0.8375\n",
      "Epoch 9/100\n",
      "79/79 [==============================] - 1s 10ms/step - loss: 227.9005 - accuracy: 0.7310 - val_loss: 242.0371 - val_accuracy: 0.8375\n",
      "Epoch 10/100\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 227.8270 - accuracy: 0.7184 - val_loss: 241.8190 - val_accuracy: 0.8375\n",
      "Epoch 11/100\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 227.9630 - accuracy: 0.7342 - val_loss: 241.8630 - val_accuracy: 0.8375\n",
      "Epoch 12/100\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 227.8419 - accuracy: 0.7278 - val_loss: 241.9224 - val_accuracy: 0.8375\n",
      "Epoch 13/100\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 227.9447 - accuracy: 0.7247 - val_loss: 241.4436 - val_accuracy: 0.8375\n",
      "Epoch 14/100\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 227.8625 - accuracy: 0.7342 - val_loss: 241.7457 - val_accuracy: 0.8375\n",
      "Epoch 15/100\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 227.8351 - accuracy: 0.7025 - val_loss: 241.4720 - val_accuracy: 0.8375\n",
      "Epoch 16/100\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 227.8517 - accuracy: 0.7310 - val_loss: 241.9096 - val_accuracy: 0.8375\n",
      "Epoch 17/100\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 227.7971 - accuracy: 0.7310 - val_loss: 241.6327 - val_accuracy: 0.8375\n",
      "Epoch 18/100\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 227.7902 - accuracy: 0.7215 - val_loss: 241.6526 - val_accuracy: 0.8375\n",
      "Epoch 19/100\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 227.7528 - accuracy: 0.7247 - val_loss: 242.0523 - val_accuracy: 0.8375\n",
      "Epoch 20/100\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 227.8457 - accuracy: 0.7310 - val_loss: 241.7571 - val_accuracy: 0.8375\n",
      "Epoch 21/100\n",
      "79/79 [==============================] - 1s 10ms/step - loss: 227.8895 - accuracy: 0.7310 - val_loss: 241.5737 - val_accuracy: 0.8375\n",
      "Epoch 22/100\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 227.7915 - accuracy: 0.7310 - val_loss: 242.0100 - val_accuracy: 0.8375\n",
      "Epoch 23/100\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 227.9023 - accuracy: 0.7152 - val_loss: 241.4250 - val_accuracy: 0.8375\n",
      "Epoch 24/100\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 227.8207 - accuracy: 0.7278 - val_loss: 241.5298 - val_accuracy: 0.8375\n",
      "Epoch 25/100\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 227.7988 - accuracy: 0.7278 - val_loss: 241.9326 - val_accuracy: 0.8375\n",
      "Epoch 26/100\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 227.8419 - accuracy: 0.7152 - val_loss: 241.9532 - val_accuracy: 0.8375\n",
      "Epoch 27/100\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 227.7870 - accuracy: 0.7152 - val_loss: 241.5414 - val_accuracy: 0.8375\n",
      "Epoch 28/100\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 227.8681 - accuracy: 0.7278 - val_loss: 241.5498 - val_accuracy: 0.8375\n",
      "Epoch 29/100\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 227.8082 - accuracy: 0.7278 - val_loss: 241.8919 - val_accuracy: 0.8375\n",
      "Epoch 30/100\n",
      "79/79 [==============================] - 1s 11ms/step - loss: 227.8333 - accuracy: 0.7247 - val_loss: 242.1378 - val_accuracy: 0.8375\n",
      "Epoch 31/100\n",
      "79/79 [==============================] - 1s 11ms/step - loss: 227.7612 - accuracy: 0.7310 - val_loss: 241.4251 - val_accuracy: 0.8375\n",
      "Epoch 32/100\n",
      "79/79 [==============================] - 1s 12ms/step - loss: 227.8046 - accuracy: 0.7278 - val_loss: 242.0254 - val_accuracy: 0.8375\n",
      "Epoch 33/100\n",
      "79/79 [==============================] - 1s 10ms/step - loss: 227.8018 - accuracy: 0.7310 - val_loss: 241.4864 - val_accuracy: 0.8375\n",
      "Epoch 34/100\n",
      "79/79 [==============================] - 1s 10ms/step - loss: 227.7476 - accuracy: 0.7089 - val_loss: 241.4545 - val_accuracy: 0.8375\n",
      "Epoch 35/100\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 227.7313 - accuracy: 0.7184 - val_loss: 242.2872 - val_accuracy: 0.8375\n",
      "Epoch 36/100\n",
      "79/79 [==============================] - 1s 7ms/step - loss: 227.7016 - accuracy: 0.7089 - val_loss: 242.0446 - val_accuracy: 0.8375\n",
      "Epoch 37/100\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 227.8013 - accuracy: 0.7342 - val_loss: 241.7947 - val_accuracy: 0.8375\n",
      "Epoch 38/100\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 227.6697 - accuracy: 0.7247 - val_loss: 241.5504 - val_accuracy: 0.8375\n",
      "Epoch 39/100\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 227.6652 - accuracy: 0.7278 - val_loss: 242.2617 - val_accuracy: 0.8375\n",
      "Epoch 40/100\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 227.7030 - accuracy: 0.7215 - val_loss: 242.0128 - val_accuracy: 0.8375\n",
      "Epoch 41/100\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 227.7223 - accuracy: 0.7310 - val_loss: 241.8385 - val_accuracy: 0.8375\n",
      "Epoch 42/100\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 227.6946 - accuracy: 0.7310 - val_loss: 242.2960 - val_accuracy: 0.8375\n",
      "Epoch 43/100\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 227.7223 - accuracy: 0.7310 - val_loss: 242.5315 - val_accuracy: 0.8375\n",
      "Epoch 44/100\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 227.6541 - accuracy: 0.7057 - val_loss: 242.7450 - val_accuracy: 0.8375\n",
      "Epoch 45/100\n",
      "79/79 [==============================] - 1s 7ms/step - loss: 227.7522 - accuracy: 0.7057 - val_loss: 242.1895 - val_accuracy: 0.8375\n",
      "Epoch 46/100\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 227.6052 - accuracy: 0.7278 - val_loss: 242.3194 - val_accuracy: 0.7375\n",
      "Epoch 47/100\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 227.5662 - accuracy: 0.7089 - val_loss: 241.7072 - val_accuracy: 0.8375\n",
      "Epoch 48/100\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 227.6240 - accuracy: 0.7184 - val_loss: 242.3210 - val_accuracy: 0.8375\n",
      "Epoch 49/100\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 227.5802 - accuracy: 0.7278 - val_loss: 242.8349 - val_accuracy: 0.8375\n",
      "Epoch 50/100\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 227.6653 - accuracy: 0.7405 - val_loss: 242.0841 - val_accuracy: 0.8375\n",
      "Epoch 51/100\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 227.6693 - accuracy: 0.6835 - val_loss: 242.2677 - val_accuracy: 0.8375\n",
      "Epoch 52/100\n",
      "79/79 [==============================] - 1s 7ms/step - loss: 227.5044 - accuracy: 0.7152 - val_loss: 242.3717 - val_accuracy: 0.8375\n",
      "Epoch 53/100\n",
      "79/79 [==============================] - 1s 7ms/step - loss: 227.4233 - accuracy: 0.7342 - val_loss: 242.6079 - val_accuracy: 0.8250\n",
      "Epoch 54/100\n",
      "79/79 [==============================] - 1s 7ms/step - loss: 227.4442 - accuracy: 0.7278 - val_loss: 243.1508 - val_accuracy: 0.8375\n",
      "Epoch 55/100\n",
      "79/79 [==============================] - 1s 6ms/step - loss: 227.3923 - accuracy: 0.7120 - val_loss: 244.6985 - val_accuracy: 0.7750\n",
      "Epoch 56/100\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 227.3407 - accuracy: 0.7310 - val_loss: 244.1143 - val_accuracy: 0.7750\n",
      "Epoch 57/100\n",
      "79/79 [==============================] - 1s 11ms/step - loss: 227.3711 - accuracy: 0.7215 - val_loss: 243.6071 - val_accuracy: 0.8375\n",
      "Epoch 58/100\n",
      "79/79 [==============================] - 1s 7ms/step - loss: 227.3613 - accuracy: 0.7278 - val_loss: 243.9090 - val_accuracy: 0.7750\n",
      "Epoch 59/100\n",
      "79/79 [==============================] - 1s 7ms/step - loss: 227.3392 - accuracy: 0.7152 - val_loss: 243.3743 - val_accuracy: 0.8375\n",
      "Epoch 60/100\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 227.2614 - accuracy: 0.7342 - val_loss: 244.2951 - val_accuracy: 0.8375\n",
      "Epoch 61/100\n",
      "79/79 [==============================] - 1s 7ms/step - loss: 227.2205 - accuracy: 0.7152 - val_loss: 243.5434 - val_accuracy: 0.6500\n",
      "Epoch 62/100\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 227.1262 - accuracy: 0.7089 - val_loss: 243.7926 - val_accuracy: 0.8375\n",
      "Epoch 63/100\n",
      "79/79 [==============================] - 1s 7ms/step - loss: 227.1629 - accuracy: 0.7184 - val_loss: 244.3149 - val_accuracy: 0.8375\n",
      "Epoch 64/100\n",
      "79/79 [==============================] - 1s 7ms/step - loss: 227.2950 - accuracy: 0.7405 - val_loss: 245.1463 - val_accuracy: 0.8375\n",
      "Epoch 65/100\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 227.0901 - accuracy: 0.7089 - val_loss: 243.3022 - val_accuracy: 0.8375\n",
      "Epoch 66/100\n",
      "79/79 [==============================] - 1s 7ms/step - loss: 227.0534 - accuracy: 0.7152 - val_loss: 246.3073 - val_accuracy: 0.5000\n",
      "Epoch 67/100\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 226.9837 - accuracy: 0.7120 - val_loss: 245.0735 - val_accuracy: 0.7750\n",
      "Epoch 68/100\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 227.0016 - accuracy: 0.7215 - val_loss: 243.9369 - val_accuracy: 0.6875\n",
      "Epoch 69/100\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 226.9973 - accuracy: 0.6867 - val_loss: 245.3154 - val_accuracy: 0.5000\n",
      "Epoch 70/100\n",
      "79/79 [==============================] - 1s 10ms/step - loss: 226.9827 - accuracy: 0.7120 - val_loss: 245.6606 - val_accuracy: 0.8375\n",
      "Epoch 71/100\n",
      "79/79 [==============================] - 1s 7ms/step - loss: 227.0342 - accuracy: 0.7089 - val_loss: 245.8452 - val_accuracy: 0.6750\n",
      "Epoch 72/100\n",
      "79/79 [==============================] - 1s 7ms/step - loss: 227.0372 - accuracy: 0.7089 - val_loss: 248.2006 - val_accuracy: 0.7375\n",
      "Epoch 73/100\n",
      "79/79 [==============================] - 1s 6ms/step - loss: 227.0768 - accuracy: 0.7057 - val_loss: 248.5646 - val_accuracy: 0.7750\n",
      "Epoch 74/100\n",
      "79/79 [==============================] - 1s 7ms/step - loss: 227.0867 - accuracy: 0.7120 - val_loss: 244.9223 - val_accuracy: 0.8375\n",
      "Epoch 75/100\n",
      "79/79 [==============================] - 1s 7ms/step - loss: 226.9726 - accuracy: 0.7152 - val_loss: 249.0844 - val_accuracy: 0.8375\n",
      "Epoch 76/100\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 226.7658 - accuracy: 0.7184 - val_loss: 249.5412 - val_accuracy: 0.8375\n",
      "Epoch 77/100\n",
      "79/79 [==============================] - 1s 6ms/step - loss: 226.8323 - accuracy: 0.7215 - val_loss: 248.1703 - val_accuracy: 0.8375\n",
      "Epoch 78/100\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 226.6940 - accuracy: 0.7120 - val_loss: 250.1779 - val_accuracy: 0.8375\n",
      "Epoch 79/100\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 226.7826 - accuracy: 0.7089 - val_loss: 250.6725 - val_accuracy: 0.8375\n",
      "Epoch 80/100\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 226.7962 - accuracy: 0.7057 - val_loss: 250.1436 - val_accuracy: 0.8375\n",
      "Epoch 81/100\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 226.7003 - accuracy: 0.7278 - val_loss: 250.2596 - val_accuracy: 0.8375\n",
      "Epoch 82/100\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 226.6677 - accuracy: 0.7057 - val_loss: 251.7690 - val_accuracy: 0.8375\n",
      "Epoch 83/100\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 226.8915 - accuracy: 0.7247 - val_loss: 249.9475 - val_accuracy: 0.6375\n",
      "Epoch 84/100\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 226.6282 - accuracy: 0.7057 - val_loss: 250.6751 - val_accuracy: 0.8375\n",
      "Epoch 85/100\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 226.6935 - accuracy: 0.7215 - val_loss: 250.0224 - val_accuracy: 0.8375\n",
      "Epoch 86/100\n",
      "79/79 [==============================] - 1s 10ms/step - loss: 226.7119 - accuracy: 0.7278 - val_loss: 249.8672 - val_accuracy: 0.6750\n",
      "Epoch 87/100\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 226.5502 - accuracy: 0.7184 - val_loss: 253.1088 - val_accuracy: 0.8375\n",
      "Epoch 88/100\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 226.6909 - accuracy: 0.7120 - val_loss: 251.2062 - val_accuracy: 0.8375\n",
      "Epoch 89/100\n",
      "79/79 [==============================] - 1s 7ms/step - loss: 226.6041 - accuracy: 0.7247 - val_loss: 252.6910 - val_accuracy: 0.8375\n",
      "Epoch 90/100\n",
      "79/79 [==============================] - 1s 7ms/step - loss: 226.5190 - accuracy: 0.7120 - val_loss: 252.0921 - val_accuracy: 0.8375\n",
      "Epoch 91/100\n",
      "79/79 [==============================] - 1s 7ms/step - loss: 226.4359 - accuracy: 0.7247 - val_loss: 253.7460 - val_accuracy: 0.8375\n",
      "Epoch 92/100\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 227.0028 - accuracy: 0.7310 - val_loss: 249.2699 - val_accuracy: 0.7750\n",
      "Epoch 93/100\n",
      "79/79 [==============================] - 1s 7ms/step - loss: 226.5607 - accuracy: 0.7278 - val_loss: 253.3064 - val_accuracy: 0.8375\n",
      "Epoch 94/100\n",
      "79/79 [==============================] - 1s 7ms/step - loss: 227.0898 - accuracy: 0.7215 - val_loss: 251.1418 - val_accuracy: 0.8375\n",
      "Epoch 95/100\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 226.9872 - accuracy: 0.6994 - val_loss: 253.0027 - val_accuracy: 0.8375\n",
      "Epoch 96/100\n",
      "79/79 [==============================] - 1s 7ms/step - loss: 226.5996 - accuracy: 0.7184 - val_loss: 253.2895 - val_accuracy: 0.8375\n",
      "Epoch 97/100\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 226.4259 - accuracy: 0.7247 - val_loss: 253.5355 - val_accuracy: 0.8375\n",
      "Epoch 98/100\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 226.5649 - accuracy: 0.7089 - val_loss: 251.9890 - val_accuracy: 0.7625\n",
      "Epoch 99/100\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 226.4771 - accuracy: 0.7215 - val_loss: 253.2511 - val_accuracy: 0.8375\n",
      "Epoch 100/100\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 226.3017 - accuracy: 0.7310 - val_loss: 253.9127 - val_accuracy: 0.8375\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1c0673b9be0>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=100, batch_size=1, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4c384453-35e2-428d-91b1-7047bf20cee7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 5 6 4]\n"
     ]
    }
   ],
   "source": [
    "print(np.array([1, 5, 6, 4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "26f726a0-1de7-4342-a47b-7779cd57a4b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 1s/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[[0.28266168, 0.26935023, 0.24484171, 0.18181695, 0.02044935,\n",
       "         0.00088007],\n",
       "        [0.30682713, 0.2626866 , 0.23476271, 0.17367081, 0.02059584,\n",
       "         0.00145697],\n",
       "        [0.29947054, 0.261554  , 0.23333973, 0.168143  , 0.02955536,\n",
       "         0.00793731],\n",
       "        [0.29025185, 0.2583913 , 0.23702428, 0.17670055, 0.02843049,\n",
       "         0.00920159]]], dtype=float32)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(np.array([[11, 51, 24, 46]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8af1afb-6910-4072-9838-a97f025ead6b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
